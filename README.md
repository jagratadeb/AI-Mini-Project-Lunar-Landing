# ğŸš€ Deep Q-Learning for Lunar Landing ğŸŒ•

This project implements a **Deep Q-Learning (DQN)** agent to solve the **LunarLander** environment from **Gymnasium**.  
The mission: ğŸ›°ï¸ train an AI pilot that learns to land a spacecraft safely on a designated landing pad using **reinforcement learning**.

---

## ğŸ§  Key Concepts & Features

- ğŸ’¡ **Reinforcement Learning (RL):**  
  The agent learns through *trial and error* â€” receiving **rewards** for good actions (landing smoothly) and **penalties** for bad ones (crashing ğŸ’¥).

- ğŸ¤– **Deep Q-Learning (DQN):**  
  Uses a **neural network** to approximate the optimal Q-function, predicting the expected future reward for each possible action.

- ğŸ§© **Neural Network Architecture:**  
  A **feed-forward network** maps environment states â†’ Q-values for all actions.

- ğŸ” **Experience Replay:**  
  Stores past experiences `(state, action, reward, next_state, done)` in a **replay buffer**, sampling random batches for **stable training**.

- ğŸ¯ **Target Network:**  
  A second network used to compute target Q-values â€” updated periodically to **stabilize** learning.

- âš–ï¸ **Epsilon-Greedy Policy:**  
  Balances **exploration** (trying new things) and **exploitation** (using what itâ€™s learned), with **epsilon decaying** over time.

- ğŸŒŠ **Soft Updates:**  
  Smoothly updates target network weights to prevent oscillations during learning.

- âš™ï¸ **Optimizer:**  
  Uses **Adam** optimizer and **Mean Squared Error (MSE)** loss for weight updates.

---

## ğŸ“¦ Dependencies

These key libraries are required for the project:

| Library | Version | Purpose |
|----------|----------|----------|
| ğŸ§© Gymnasium | 1.2.2 | Environment simulation (`LunarLander`) |
| ğŸ”¥ PyTorch | latest (CUDA compatible) | Deep learning models |
| ğŸ”¢ NumPy | 2.0.2 | Numerical operations |
| âš™ï¸ Box2D-py | 2.3.5 | Physics engine |
| ğŸ§° SWIG | 4.4.0 | Dependency for Box2D |
| ğŸ¥ Imageio | â€” | For saving gameplay videos |
| ğŸ“Š Matplotlib | â€” | For training score plots |

---



